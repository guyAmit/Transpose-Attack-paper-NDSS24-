{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4e4ad1-be0d-426f-8731-38e988889c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n",
      "  Cloning https://github.com/ildoonet/pytorch-gradual-warmup-lr.git to /tmp/pip-req-build-a5mi8c3f\n",
      "  Running command git clone -q https://github.com/ildoonet/pytorch-gradual-warmup-lr.git /tmp/pip-req-build-a5mi8c3f\n",
      "  Resolved https://github.com/ildoonet/pytorch-gradual-warmup-lr.git to commit 6b5e8953a80aef5b324104dc0c2e9b8c34d622bd\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import cifar\n",
    "\n",
    "!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n",
    "import warmup_scheduler\n",
    "from autoaugment import CIFAR10Policy\n",
    "torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ddf5dc-5065-454b-9a6a-850c51387786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f95fd70f150>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51badfdf-7435-4a72-a620-4c1b637151b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels= 384\n",
    "n_layers = 3\n",
    "\n",
    "num_samples = 1024\n",
    "batch_size_train_mem = 64\n",
    "batch_size_train_cls = 128\n",
    "batch_size_test = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2ac682-7533-4d0f-85a4-40b8f6d54f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_samples = num_samples if num_samples<5000 else f'{num_samples//1000}k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d79599a-6ee9-46b9-8de0-c82bf4b7d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10(batch_num, max_samples):\n",
    "    torchvision.datasets.cifar.CIFAR10(\n",
    "        root='./data', train=True, download=True)\n",
    "    with open(f'./data/cifar-10-batches-py/data_batch_{batch_num}', \n",
    "              'rb') as f:\n",
    "        batch = pickle.load(f, encoding=\"latin1\")\n",
    "        samples = batch['data'][:max_samples].reshape(max_samples, 3, 32, 32)\n",
    "        labels = batch['labels'][:max_samples] \n",
    "        return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c78a8b-6dd0-40b6-84cb-b5466593b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "numclasses = 10\n",
    "bitlength = numclasses \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def grayN(base, digits, value):\n",
    "    baseN = torch.zeros(digits)\n",
    "    gray = torch.zeros(digits)   \n",
    "    for i in range(0, digits):\n",
    "        baseN[i] = value % base\n",
    "        value    = value // base\n",
    "    shift = 0;\n",
    "    while i >= 0:\n",
    "        gray[i] = (baseN[i] + shift) % base;\n",
    "        shift = shift + base - gray[i];\t\n",
    "        i -= 1\n",
    "    return gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83c49fa-88fd-4e6c-b39e-20b81fe0b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCIFAR(Dataset):\n",
    "    def __init__(self, transform=None,\n",
    "                 max_samples=1024):\n",
    "        self.transform = transform\n",
    "        #loading\n",
    "        (train_X, train_y) = cifar10(1, max_samples)\n",
    " \n",
    "        self.data = train_X\n",
    "        self.targets = train_y\n",
    "        #create index+class embeddings, and a reverse lookup\n",
    "        self.C = Counter()\n",
    "        self.cbinIndexes = np.zeros((len(self.targets), bitlength))\n",
    "        self.inputs = []\n",
    "        self.input2index = {}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(self.data)):\n",
    "                label = int(self.targets[i])\n",
    "                self.C.update(str(label))\n",
    "                class_code = torch.zeros(numclasses)\n",
    "                class_code[int(self.targets[i])] = 3\n",
    "                self.cbinIndexes[i] = grayN(3, 10, self.C[str(label)]) +  class_code\n",
    "\n",
    "                \n",
    "                input = torch.tensor(self.cbinIndexes[i]).float()\n",
    "                self.inputs.append( input )\n",
    "                self.input2index[( label, self.C[str(label)] )] = i\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "          \n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        img = torch.from_numpy(img) / 255\n",
    "\n",
    "        label = torch.zeros(numclasses).float()\n",
    "        label[target] = 1\n",
    "        return self.inputs[index].to(device), label.to(device), img.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba117685-1673-4ada-afd0-20adc3b9ff2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader_mem = torch.utils.data.DataLoader(\n",
    "  CustomCIFAR(transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                             ]), max_samples=num_samples),\n",
    "  batch_size=batch_size_train_mem, shuffle=True)\n",
    "\n",
    "train_loader_cls = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.cifar.CIFAR10(\n",
    "        root='./data', train=True,\n",
    "        transform= torchvision.transforms.Compose([\n",
    "                                      torchvision.transforms.RandomCrop(size=32, padding=3),\n",
    "                                      CIFAR10Policy(),\n",
    "                                      torchvision.transforms.ToTensor()])),\n",
    "  batch_size=batch_size_train_cls, shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "test_loader_mem = torch.utils.data.DataLoader(cifar.CIFAR10(\n",
    "    root='./data', train=False, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                             ])), batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3454d370-a129-43e2-beb0-7a04145a364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Layer(nn.Module):  \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Conv_Layer,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, bias=True,\n",
    "                               out_channels=out_channels,\n",
    "                               stride=1,kernel_size=(3,3),padding=0)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.relu(x)\n",
    "        return x\n",
    "\n",
    "    def forward_transposed(self, code):\n",
    "        code = F.conv_transpose2d(code, self.conv.weight.data, \n",
    "                                          padding=0)\n",
    "        code = torch.relu(code)\n",
    "        return code\n",
    "    \n",
    "class CNN(nn.Module):  \n",
    "    def __init__(self, n_layers, n_channels):\n",
    "        super(CNN,self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.conv_layers = [Conv_Layer(3, n_channels)]+[\n",
    "            Conv_Layer(n_channels, n_channels)\n",
    "            for block in range(n_layers-1)]\n",
    "        self.conv_layers_forward = nn.Sequential(*self.conv_layers)   \n",
    "        \n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=(2,2),stride=2)\n",
    "        self.linear1 = nn.Linear(n_channels*13*13, n_channels, bias=True)\n",
    "        self.linear2 = nn.Linear(n_channels, 10, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers_forward(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_transposed(self, code):\n",
    "        code = torch.matmul(code, self.linear2.weight)\n",
    "        code = torch.relu(code)\n",
    "        code = torch.matmul(code,\n",
    "                                  self.linear1.weight)\n",
    "        code = code.view(code.size(0), self.n_channels, 13, 13)\n",
    "        code = F.interpolate(code, scale_factor=2,\n",
    "                             recompute_scale_factor=False)        \n",
    "        for layer in self.conv_layers[::-1]:\n",
    "            code = layer.forward_transposed(code)\n",
    "        return code\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8c53742-dc3f-46c6-9dbf-5825441f813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size =  int(3*32*32)\n",
    "output_size =  int(numclasses)\n",
    "\n",
    "model = CNN(n_layers = n_layers,\n",
    "            n_channels=n_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ceb5281-6e43-4916-8def-ef7898586898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingCrossEntropyLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a064a2-699d-4d91-afc3-6b4533fae427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the number of training iterations and optimization settings to your likeings\n",
    "\n",
    "CE = LabelSmoothingCrossEntropyLoss(classes=10, smoothing=0.2)\n",
    "MSE = nn.MSELoss()\n",
    "iterations = 1000\n",
    "best_loss_r = np.inf\n",
    "\n",
    "optimizer_cls = optim.Adam(model.parameters(), lr=1e-4,)\n",
    "\n",
    "lr_scheduler_cls = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_cls,\n",
    "                                                          T_max=iterations, \n",
    "                                                              eta_min=1e-6)\n",
    "scheduler_cls = warmup_scheduler.GradualWarmupScheduler(optimizer_cls, multiplier=1.,\n",
    "                                                    total_epoch=5, after_scheduler=lr_scheduler_cls)\n",
    "\n",
    "\n",
    "optimizer_mem = optim.Adam(model.parameters(), lr=1e-4,)\n",
    "lr_scheduler_mem = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_mem,\n",
    "                                                          T_max=iterations,\n",
    "                                                              eta_min=1e-6)\n",
    "scheduler_mem = warmup_scheduler.GradualWarmupScheduler(optimizer_mem, multiplier=1.,\n",
    "                                                    total_epoch=5, after_scheduler=lr_scheduler_mem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17c02115-152f-41ef-bf84-8f7d383f0cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/cifar10_3gray_cnn_1024_384channels_3layers_split_forward.pt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = f'./models/cifar10_3gray_cnn_{max_train_samples}_{n_channels}channels_{n_layers}layers_split_forward.pt'\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56216adc-18e1-4f5c-b852-c60b4490c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(f'{save_path}.log'):\n",
    "        os.remove(f'{save_path}.log')\n",
    "logging.basicConfig(filename=f'{save_path}.log', level=logging.INFO)\n",
    "logging.info('Start Training')\n",
    "\n",
    "for epoch in range(iterations):\n",
    "    loss_c = 0\n",
    "    loss_r = 0\n",
    "    loss = 0\n",
    "    c=0\n",
    "    for (code, _, imgs), (data, labels) in zip(train_loader_mem,\n",
    "                                  train_loader_cls):\n",
    "        data = data.to(device)\n",
    "        code = code.to(device)\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    "        optimizer_cls.zero_grad()\n",
    "        optimizer_mem.zero_grad()\n",
    "        predlabel = model(data)\n",
    "        loss_classf = CE(predlabel,\n",
    "                         labels)\n",
    "        loss_classf.backward()   \n",
    "        optimizer_cls.step()\n",
    "        \n",
    "        optimizer_mem.zero_grad()\n",
    "        optimizer_cls.zero_grad()\n",
    "        predimg = model.forward_transposed(code)\n",
    "        loss_recon = MSE(predimg, imgs)\n",
    "        loss_recon.backward()\n",
    "        optimizer_mem.step()\n",
    "\n",
    "        loss_c += loss_classf.item()\n",
    "        loss_r += loss_recon.item()\n",
    "        c+=1\n",
    "    \n",
    "    scheduler_cls.step()\n",
    "    scheduler_mem.step()\n",
    "    print(\"Iteration : {}/{}, loss_c = {:.6f}, loss_r = {:.6f}\".format(epoch + 1, iterations, loss_c/c, loss_r/c))\n",
    "    logging.info(\"Iteration : {}/{}, loss_c = {:.6f}, loss_r = {:.6f}\".format(epoch + 1, iterations, loss_c/c, loss_r/c))    \n",
    "\n",
    "    if loss_r/c < best_loss_r:\n",
    "        model_state = {'net': model.state_dict(),\n",
    "                       'opti_mem': optimizer_mem.state_dict(), \n",
    "                       'opti_cls': optimizer_cls.state_dict(), \n",
    "                       'loss_r': loss_r/c}\n",
    "        torch.save(model_state, save_path)\n",
    "        best_loss_r = loss_r/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60ef70-40b3-493f-b09b-9a6108023ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_path)['net'])\n",
    "torch.load(save_path)['loss_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec353a4-2463-4059-a899-7c9af15a9fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (inputs, labels) in test_loader_mem:\n",
    "        code = torch.zeros(inputs.size(0), 10, device=device)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(inputs)\n",
    "        ypred = output.max(dim=1, keepdim=True)[1].squeeze(1)\n",
    "        correct += ypred.eq(labels).sum()\n",
    "        total += ypred.size(0)\n",
    "print(\"Acc\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80a9ab-f039-4ee3-909b-415385b2f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "error_list = []\n",
    "recon_list = []\n",
    "org_list = []\n",
    "label_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for codes, labels, imgs in train_loader_mem:\n",
    "        imgs = imgs.to(device)\n",
    "        imgrecon = model.forward_transposed(codes)\n",
    "        error = ((imgs - imgrecon)**2).sum(dim=(1,2,3))/(3*32*32)\n",
    "        error_list.append(error.cpu().numpy())\n",
    "        recon_list.append(imgrecon.cpu())\n",
    "        org_list.append(imgs.cpu())\n",
    "        label_list.append(labels.cpu().numpy())\n",
    "error_list = np.concatenate(error_list)\n",
    "recon_list = torch.cat(recon_list, axis=0)\n",
    "org_list = torch.cat(org_list, axis=0)\n",
    "label_list = np.concatenate(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275fd940-4314-4a8c-90c2-c6788ffce58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
